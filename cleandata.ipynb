{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from tokenize import tokenize, untokenize\n",
    "\n",
    "\n",
    "import pandas, numpy, string\n",
    "\n",
    "\n",
    "\n",
    "def dataparser(filename):\n",
    "    with open(filename,'r') as fo:\n",
    "        sgml=fo.read()\n",
    "    soup = BeautifulSoup(sgml,'html.parser')\n",
    "    text_list=soup.find_all('text')\n",
    "    label_list=soup.find_all('topics')\n",
    "    \n",
    "   \n",
    "    tabbrut = []\n",
    "    tablabel =[]\n",
    "    tablabel2 =[]\n",
    "    for item2 in label_list:\n",
    "        lines_in_item2 = item2.text.split('\\n')\n",
    "        for g in lines_in_item2:\n",
    "            tablabel.append(g)\n",
    "            if(g !=\"\"):\n",
    "                tablabel2.append(g)\n",
    "                \n",
    "    \n",
    "    tabtext =[]\n",
    "  \n",
    "    set(stopwords.words('english'))\n",
    "    \n",
    "    a=0       \n",
    "    for x in tablabel :\n",
    "        if(x !=''):\n",
    "            tabbrut.append(str(text_list[a]))\n",
    "            tabtext.append(str(text_list[a]))\n",
    "            \n",
    "          \n",
    "        a+=1 \n",
    "        \n",
    "    tabtext45 = [\"\" for i in range(0,len(tabtext))]\n",
    "    p=0\n",
    "    for k in tabtext:\n",
    "        word_token = word_tokenize(k)\n",
    "        k = [word for word in word_token if not word  in stopwords.words('english')]\n",
    "        for l in k:\n",
    "            \n",
    "            tabtext[p] += \" \" + l\n",
    "        p+=1\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "    return tabtext, tablabel2, tabbrut\n",
    "\n",
    "Matrix0T, Matrix0L, Matrix0I = dataparser(r'C:\\Users\\Victor\\Downloads\\reuters21578\\reut2-000.sgm')\n",
    "Matrix1T, Matrix1L,Matrix1I = dataparser(r'C:\\Users\\Victor\\Downloads\\reuters21578\\reut2-001.sgm')\n",
    "Matrix2T, Matrix2L,Matrix2I = dataparser(r'C:\\Users\\Victor\\Downloads\\reuters21578\\reut2-002.sgm')\n",
    "Matrix3T, Matrix3L,Matrix3I = dataparser(r'C:\\Users\\Victor\\Downloads\\reuters21578\\reut2-003.sgm')\n",
    "Matrix4T, Matrix4L,Matrix4I = dataparser(r'C:\\Users\\Victor\\Downloads\\reuters21578\\reut2-004.sgm')\n",
    "Matrix5T, Matrix5L,Matrix5I = dataparser(r'C:\\Users\\Victor\\Downloads\\reuters21578\\reut2-005.sgm')\n",
    "Matrix6T, Matrix6L,Matrix6I = dataparser(r'C:\\Users\\Victor\\Downloads\\reuters21578\\reut2-006.sgm')\n",
    "Matrix7T, Matrix7L,Matrix7I = dataparser(r'C:\\Users\\Victor\\Downloads\\reuters21578\\reut2-007.sgm')\n",
    "Matrix8T, Matrix8L,Matrix8I = dataparser(r'C:\\Users\\Victor\\Downloads\\reuters21578\\reut2-008.sgm')\n",
    "Matrix9T, Matrix9L,Matrix9I = dataparser(r'C:\\Users\\Victor\\Downloads\\reuters21578\\reut2-009.sgm')\n",
    "Matrix10T, Matrix10L,Matrix10I = dataparser(r'C:\\Users\\Victor\\Downloads\\reuters21578\\reut2-010.sgm')\n",
    "Matrix11T, Matrix11L,Matrix11I = dataparser(r'C:\\Users\\Victor\\Downloads\\reuters21578\\reut2-011.sgm')\n",
    "Matrix12T, Matrix12L,Matrix12I = dataparser(r'C:\\Users\\Victor\\Downloads\\reuters21578\\reut2-012.sgm')\n",
    "Matrix13T, Matrix13L,Matrix13I = dataparser(r'C:\\Users\\Victor\\Downloads\\reuters21578\\reut2-013.sgm')\n",
    "Matrix14T, Matrix14L, Matrix14I = dataparser(r'C:\\Users\\Victor\\Downloads\\reuters21578\\reut2-014.sgm')\n",
    "Matrix17T, Matrix17L,Matrix17I = dataparser(r'C:\\Users\\Victor\\Downloads\\reuters21578\\reut2-017.sgm')\n",
    "\n",
    "Train = [*Matrix0T,*Matrix1T,*Matrix2T,*Matrix3T,*Matrix4T,*Matrix5T,*Matrix6T,*Matrix7T,*Matrix8T,*Matrix9T,*Matrix10T,*Matrix11T,*Matrix12T,*Matrix13T,*Matrix14T,*Matrix17T]\n",
    "\n",
    "Label =[ *Matrix0L,*Matrix1L,*Matrix2L,*Matrix3L,*Matrix4L,*Matrix5L,*Matrix6L,*Matrix7L,*Matrix8L,*Matrix9L,*Matrix10L,*Matrix11L,*Matrix12L,*Matrix13L,*Matrix14L,*Matrix17L]\n",
    "\n",
    "\n",
    "Matrix15T, Matrix15L,Matrix15I = dataparser(r'C:\\Users\\Victor\\Downloads\\reuters21578\\reut2-015.sgm')\n",
    "Matrix16T, Matrix16L,Matrix16I = dataparser(r'C:\\Users\\Victor\\Downloads\\reuters21578\\reut2-016.sgm')\n",
    "Matrix18T, Matrix18L,Matrix18I = dataparser(r'C:\\Users\\Victor\\Downloads\\reuters21578\\reut2-018.sgm')\n",
    "Matrix19T, Matrix19L,Matrix19I = dataparser(r'C:\\Users\\Victor\\Downloads\\reuters21578\\reut2-019.sgm')\n",
    "Matrix20T, Matrix20L,Matrix20I = dataparser(r'C:\\Users\\Victor\\Downloads\\reuters21578\\reut2-020.sgm')\n",
    "Matrix21T, Matrix21L,Matrix21I = dataparser(r'C:\\Users\\Victor\\Downloads\\reuters21578\\reut2-021.sgm')\n",
    "\n",
    "Test = [*Matrix15T, *Matrix16T, *Matrix18T,*Matrix19T,*Matrix20T,*Matrix21T]\n",
    "\n",
    "Answer = [*Matrix15L, *Matrix16L,*Matrix18L,*Matrix19L,*Matrix20L,*Matrix21L]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "590"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Matrix17T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'acq'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix19L[320]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(TfidfVectorizer(),MultinomialNB())\n",
    "model.fit(Train , Label)\n",
    "labels = model.predict(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5713772024451637"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=0\n",
    "accuracy=0\n",
    "for x in labels:\n",
    "    if (x == str(Answer[a])):\n",
    "         accuracy +=1\n",
    "    a+=1\n",
    "    \n",
    "accuracy/ len(Answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1036"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512+524"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
